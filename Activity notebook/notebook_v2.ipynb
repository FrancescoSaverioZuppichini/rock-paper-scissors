{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building a convnet for ✊✋✌\n",
    "This presents how to build a convnet from scratch to classify images of rock-paper-scissors.  It is meant as a teaching activity to demonstrate the following concepts in practice:\n",
    "- how images are represented and handled in software\n",
    "- how to prepare a machine learning dataset\n",
    "- how a full machine learning pipeline looks\n",
    "- data preprocessing\n",
    "- data augmentation and its importance in a \n",
    "- overfitting, underfitting\n",
    "\n",
    "We use the high-level deep learning library Keras, but the concepts are general and we don't put much focus on the specifics of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 0: defining the problem\n",
    "What problem do we want to solve, exactly?  We want to build a piece of software that, given an image as input that represents an hand making one of the three ✊✋✌ gestures, produces as output a classification of the image in one of the three classes.\n",
    "\n",
    "In the following, we will adopt this convention\n",
    "- class 0 is ✊ rock\n",
    "- class 1 is ✋ paper\n",
    "- class 2 is ✌ scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 1: building a dataset\n",
    "We are starting from scratch, so we need to shoot our own dataset; the best option is that multiple students/groups shoot plenty of images in parallel and then the data is somehow collected.  Whatever the process, in the end we want to have all pics in three different directories, one per class.  Format can be either jpg or png, and landscape/portrait, aspect ratio and resolution don't matter and can be mixed.\n",
    "\n",
    "With some attention to logistics, this can be done in about 10-30 minutes.\n",
    "\n",
    "Guidelines for shooting images. \n",
    "- We don't need high resolution: use the lowest resolution/quality allowed by the phone (this reduces the size of the dataset and speeds up data transfer).\n",
    "- The hand must be more or less in the center of the image; it should not fill the whole image, but it should not be too small either.  ![caption](figures/guidelines.jpg)\n",
    "- we want the dataset to represent as much variability as possible: if we want the classifier to work for all hand orientations, try to have examples for all of them; if we want to handle many different lightling conditions, try to have some pictures for different lightings;\n",
    "- avoid poses that are ambiguous, unless you want to make your job harder: e.g., don't include in the dataset images of paper or scissors taken from the side;\n",
    "- avoid having two images in the dataset that are almost the same: change the camera and hand pose at least a little bit; this is important because in the following code we randomly split training and testing data.\n",
    "\n",
    "Remember that we need the images for each class to be in its own directory. To make this simpler, it helps to shoot first all images of rock, then all images of paper, then all images of scissors, and finally sort the images by time in the file manager and group them accordingly.\n",
    "\n",
    "Place all images in three directories named `c0/`, `c1/`, and `c2/`.  Make sure that each directory only contains image files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2: read in images and have a look at them\n",
    "Let's first import what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrizio\\Anaconda3\\lib\\site-packages\\skimage\\viewer\\utils\\core.py:10: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warn(\"Recommended matplotlib backend is `Agg` for full \"\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# General imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import skimage.viewer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import keras.utils.np_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup to show interactive jupyter widgets\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "def imgplotList(i,data):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(data[i],interpolation=\"nearest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory ..\\datasets\\final\\D3\\c1 containing class paper\n",
      "Found directory ..\\datasets\\final\\D2\\c0 containing class rock\n",
      "Found directory ..\\datasets\\final\\D1\\c2 containing class scissors\n",
      "Found directory ..\\datasets\\final\\testing\\c1 containing class paper\n",
      "Found directory ..\\datasets\\final\\testing\\c0 containing class rock\n",
      "Found directory ..\\datasets\\final\\D6\\c0 containing class rock\n",
      "Found directory ..\\datasets\\final\\D4\\c0 containing class rock\n",
      "Found directory ..\\datasets\\final\\D7\\c2 containing class scissors\n",
      "Found directory ..\\datasets\\final\\D3\\c0 containing class rock\n",
      "Found directory ..\\datasets\\final\\D2\\c1 containing class paper\n",
      "Found directory ..\\datasets\\final\\D4\\c2 containing class scissors\n",
      "Found directory ..\\datasets\\final\\D1\\c0 containing class rock\n",
      "Found directory ..\\datasets\\final\\D5\\c0 containing class rock\n",
      "Found directory ..\\datasets\\final\\D5\\c2 containing class scissors\n",
      "Found directory ..\\datasets\\final\\D7\\c1 containing class paper\n",
      "Found directory ..\\datasets\\final\\D6\\c1 containing class paper\n",
      "Found directory ..\\datasets\\final\\D3\\c2 containing class scissors\n",
      "Found directory ..\\datasets\\final\\D2\\c2 containing class scissors\n",
      "Found directory ..\\datasets\\final\\D4\\c1 containing class paper\n",
      "Found directory ..\\datasets\\final\\D7\\c0 containing class rock\n",
      "Found directory ..\\datasets\\final\\D1\\c1 containing class paper\n",
      "Found directory ..\\datasets\\final\\D5\\c1 containing class paper\n",
      "Found directory ..\\datasets\\final\\D6\\c2 containing class scissors\n",
      "Found directory ..\\datasets\\final\\testing\\c2 containing class scissors\n"
     ]
    }
   ],
   "source": [
    "# Define where datasets are located\n",
    "dataset_directory = pathlib.Path(\"..\")/\"datasets\"/\"final\"\n",
    "\n",
    "# Define which datasets we should consider.\n",
    "# Each dataset is a directory withing dataset_directory\n",
    "# and must contain three subdirectories: (c0, c1, c2) for (rock, paper, scissors).\n",
    "dnames = [\"D{}\".format(n) for n in range(1,8)] + [\"testing\"]\n",
    "\n",
    "\n",
    "# Now check the data\n",
    "ddirs=[dataset_directory/dn for dn in dnames] # directories of the dataset\n",
    "cdirs={}\n",
    "for ddir in ddirs:\n",
    "    cdirs.update({ddir/\"c0\":0,\n",
    "                  ddir/\"c1\":1,\n",
    "                  ddir/\"c2\":2})\n",
    "names = [\"rock\", \"paper\", \"scissors\"]\n",
    "for cdir,cdir_class in cdirs.items():\n",
    "    assert(cdir.exists())\n",
    "    print(\"Found directory {} containing class {}\".format(cdir,names[cdir_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try to read the first image from the first directory, and visualize it.  Note that the tool allows you to zoom in order to see the individual pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = skimage.io.imread(list(list(cdirs.keys())[0].glob(\"*\"))[0])\n",
    "viewer=skimage.viewer.ImageViewer(im)\n",
    "viewer.show()\n",
    "# Note: you have to close the window to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We now read in all images, cut the central square (with an edge as long as the shorter dimension), and resize it to 200x200 pixels.  Whatever the initial size and orientation of the images, we will end up with a bunch of 200x200 RGB squares in uint8.  These should be small enough that unless the dataset is huge, all should fit in memory.\n",
    "\n",
    "We make a pandas dataframe with the data, with two columns:\n",
    "* image: a $200 \\times 200 \\times 3$ uint8 numpy array\n",
    "* label: on of 0, 1 or 2\n",
    "* file: the full path of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7/24 [00:19<00:46,  2.76s/it]C:\\Users\\Fabrizio\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: ignoring ..\\datasets\\final\\D7\\c2\\.DS_Store due to exception cannot identify image file 'C:\\\\Users\\\\Fabrizio\\\\Documents\\\\GitHub\\\\rock-paper-scissors\\\\datasets\\\\final\\\\D7\\\\c2\\\\.DS_Store'\n",
      "  if sys.path[0] == '':\n",
      " 58%|█████▊    | 14/24 [00:45<00:32,  3.27s/it]C:\\Users\\Fabrizio\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: ignoring ..\\datasets\\final\\D7\\c1\\.DS_Store due to exception cannot identify image file 'C:\\\\Users\\\\Fabrizio\\\\Documents\\\\GitHub\\\\rock-paper-scissors\\\\datasets\\\\final\\\\D7\\\\c1\\\\.DS_Store'\n",
      "  if sys.path[0] == '':\n",
      " 79%|███████▉  | 19/24 [01:09<00:18,  3.64s/it]C:\\Users\\Fabrizio\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: ignoring ..\\datasets\\final\\D7\\c0\\.DS_Store due to exception cannot identify image file 'C:\\\\Users\\\\Fabrizio\\\\Documents\\\\GitHub\\\\rock-paper-scissors\\\\datasets\\\\final\\\\D7\\\\c0\\\\.DS_Store'\n",
      "  if sys.path[0] == '':\n",
      "100%|██████████| 24/24 [01:35<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "imagesize = 200\n",
    "\n",
    "dataset=[]\n",
    "\n",
    "import warnings\n",
    "\n",
    "for cdir,cn in tqdm(list(cdirs.items())):\n",
    "    for f in list(cdir.glob(\"*\")):\n",
    "        try:\n",
    "            im=skimage.io.imread(f)\n",
    "        except (OSError, ValueError) as e:\n",
    "            warnings.warn(\"ignoring {} due to exception {}\".format(f,str(e)))\n",
    "            continue\n",
    "            \n",
    "        h,w=im.shape[0:2] # height, width\n",
    "        sz=min(h,w)\n",
    "        im=im[(h//2-sz//2):(h//2+sz//2),(w//2-sz//2):(w//2+sz//2),:] # defines the central square        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            im=skimage.img_as_ubyte(skimage.transform.resize(im,(imagesize,imagesize))) # resize it to 500x500, whatever the original resolution\n",
    "            \n",
    "        dataset.append({\n",
    "            \"file\":f,\n",
    "            \"label\":cn,\n",
    "            \"image\":im})\n",
    "        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We make a pandas dataframe for the dataset, and create a \"dn\" field containing the name of the dataset from which each image comes (as the name of the directory it was read from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=pd.DataFrame(dataset)\n",
    "dataset[\"dn\"]=dataset[\"file\"].apply(lambda x: x.parent.parts[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here are 10 random rows from that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >image</th> \n",
       "        <th class=\"col_heading level0 col1\" >label</th> \n",
       "        <th class=\"col_heading level0 col2\" >file</th> \n",
       "        <th class=\"col_heading level0 col3\" >dn</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row0\" >1782</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow0_col0\" class=\"data row0 col0\" >[[[ 89 106 113]\n",
       "  [ 90 107 114]\n",
       "  [ 91 108 113]\n",
       "  ..., \n",
       "  [173 140  85]\n",
       "  [171 136  84]\n",
       "  [175 140  88]]\n",
       "\n",
       " [[ 91 108 115]\n",
       "  [ 89 106 113]\n",
       "  [ 91 109 113]\n",
       "  ..., \n",
       "  [177 139  77]\n",
       "  [178 138  75]\n",
       "  [173 134  69]]\n",
       "\n",
       " [[ 91 108 115]\n",
       "  [ 92 109 116]\n",
       "  [ 91 109 113]\n",
       "  ..., \n",
       "  [174 138  73]\n",
       "  [138 104  75]\n",
       "  [ 62  29  12]]\n",
       "\n",
       " ..., \n",
       " [[212 229 237]\n",
       "  [213 230 238]\n",
       "  [213 230 238]\n",
       "  ..., \n",
       "  [ 63  89 103]\n",
       "  [ 64  90 104]\n",
       "  [ 65  91 104]]\n",
       "\n",
       " [[210 227 235]\n",
       "  [212 229 237]\n",
       "  [213 230 238]\n",
       "  ..., \n",
       "  [ 63  89 102]\n",
       "  [ 63  89 102]\n",
       "  [ 61  87 100]]\n",
       "\n",
       " [[210 227 235]\n",
       "  [211 228 236]\n",
       "  [212 229 237]\n",
       "  ..., \n",
       "  [ 63  89 102]\n",
       "  [ 63  89 102]\n",
       "  [ 61  87 100]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow0_col1\" class=\"data row0 col1\" >2</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow0_col2\" class=\"data row0 col2\" >..\\datasets\\final\\D6\\c2\\IMG_20180119_102437.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow0_col3\" class=\"data row0 col3\" >D6</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row1\" >200</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow1_col0\" class=\"data row1 col0\" >[[[154 165 171]\n",
       "  [152 159 162]\n",
       "  [160 158 160]\n",
       "  ..., \n",
       "  [164 171 177]\n",
       "  [167 174 181]\n",
       "  [173 180 188]]\n",
       "\n",
       " [[150 161 169]\n",
       "  [133 142 147]\n",
       "  [130 131 134]\n",
       "  ..., \n",
       "  [184 192 195]\n",
       "  [182 189 194]\n",
       "  [181 189 194]]\n",
       "\n",
       " [[170 183 191]\n",
       "  [166 177 182]\n",
       "  [143 151 154]\n",
       "  ..., \n",
       "  [184 190 192]\n",
       "  [184 189 192]\n",
       "  [175 180 183]]\n",
       "\n",
       " ..., \n",
       " [[178 160 160]\n",
       "  [175 157 157]\n",
       "  [173 155 155]\n",
       "  ..., \n",
       "  [ 56  64  41]\n",
       "  [ 66  76  51]\n",
       "  [ 63  73  48]]\n",
       "\n",
       " [[174 156 156]\n",
       "  [175 157 157]\n",
       "  [170 152 151]\n",
       "  ..., \n",
       "  [ 57  67  42]\n",
       "  [ 69  79  51]\n",
       "  [ 75  86  56]]\n",
       "\n",
       " [[172 154 154]\n",
       "  [171 153 153]\n",
       "  [171 153 152]\n",
       "  ..., \n",
       "  [ 45  54  30]\n",
       "  [ 51  61  32]\n",
       "  [ 68  80  49]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow1_col1\" class=\"data row1 col1\" >0</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow1_col2\" class=\"data row1 col2\" >..\\datasets\\final\\testing\\c0\\IMG_2589.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow1_col3\" class=\"data row1 col3\" >testing</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row2\" >470</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow2_col0\" class=\"data row2 col0\" >[[[ 53  67  52]\n",
       "  [ 61  75  58]\n",
       "  [ 60  76  57]\n",
       "  ..., \n",
       "  [196 189 178]\n",
       "  [178 165 157]\n",
       "  [180 167 153]]\n",
       "\n",
       " [[ 64  77  65]\n",
       "  [ 63  75  60]\n",
       "  [ 61  76  55]\n",
       "  ..., \n",
       "  [191 183 174]\n",
       "  [175 165 156]\n",
       "  [183 172 155]]\n",
       "\n",
       " [[ 53  66  50]\n",
       "  [ 68  77  60]\n",
       "  [ 68  80  60]\n",
       "  ..., \n",
       "  [175 166 158]\n",
       "  [197 191 181]\n",
       "  [189 186 170]]\n",
       "\n",
       " ..., \n",
       " [[ 20  30  37]\n",
       "  [ 26  33  38]\n",
       "  [ 26  30  39]\n",
       "  ..., \n",
       "  [ 31  45  35]\n",
       "  [ 30  41  28]\n",
       "  [ 22  36  20]]\n",
       "\n",
       " [[ 18  26  35]\n",
       "  [ 24  32  43]\n",
       "  [ 23  32  39]\n",
       "  ..., \n",
       "  [ 22  41  30]\n",
       "  [ 28  40  31]\n",
       "  [ 23  34  23]]\n",
       "\n",
       " [[ 22  32  40]\n",
       "  [ 23  34  42]\n",
       "  [ 22  34  41]\n",
       "  ..., \n",
       "  [ 22  41  31]\n",
       "  [ 27  38  30]\n",
       "  [ 32  42  30]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow2_col1\" class=\"data row2 col1\" >2</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow2_col2\" class=\"data row2 col2\" >..\\datasets\\final\\D7\\c2\\20180219134546-Scissors-9f58136563b686d7.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow2_col3\" class=\"data row2 col3\" >D7</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row3\" >1250</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow3_col0\" class=\"data row3 col0\" >[[[ 31  29  34]\n",
       "  [ 25  23  28]\n",
       "  [ 26  24  29]\n",
       "  ..., \n",
       "  [117 111 113]\n",
       "  [114 110 110]\n",
       "  [113 109 108]]\n",
       "\n",
       " [[123 114 119]\n",
       "  [122 112 117]\n",
       "  [127 117 124]\n",
       "  ..., \n",
       "  [115 109 111]\n",
       "  [114 110 111]\n",
       "  [114 110 111]]\n",
       "\n",
       " [[125 113 117]\n",
       "  [127 115 119]\n",
       "  [127 115 120]\n",
       "  ..., \n",
       "  [119 113 115]\n",
       "  [117 111 115]\n",
       "  [118 112 116]]\n",
       "\n",
       " ..., \n",
       " [[156 143 150]\n",
       "  [158 145 152]\n",
       "  [158 145 152]\n",
       "  ..., \n",
       "  [ 43  48  53]\n",
       "  [ 44  48  54]\n",
       "  [ 44  48  55]]\n",
       "\n",
       " [[152 137 144]\n",
       "  [151 137 144]\n",
       "  [155 140 147]\n",
       "  ..., \n",
       "  [ 44  49  53]\n",
       "  [ 46  50  55]\n",
       "  [ 44  47  53]]\n",
       "\n",
       " [[152 137 144]\n",
       "  [154 139 146]\n",
       "  [155 140 147]\n",
       "  ..., \n",
       "  [ 44  49  53]\n",
       "  [ 45  48  53]\n",
       "  [ 42  45  51]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow3_col1\" class=\"data row3 col1\" >2</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow3_col2\" class=\"data row3 col2\" >..\\datasets\\final\\D2\\c2\\IMG_0384.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow3_col3\" class=\"data row3 col3\" >D2</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row4\" >416</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow4_col0\" class=\"data row4 col0\" >[[[  4   3   8]\n",
       "  [  4   3   8]\n",
       "  [  4   3   8]\n",
       "  ..., \n",
       "  [ 21  21  21]\n",
       "  [ 20  21  17]\n",
       "  [ 20  20  18]]\n",
       "\n",
       " [[  3   2   7]\n",
       "  [  2   1   6]\n",
       "  [  4   3   8]\n",
       "  ..., \n",
       "  [ 22  23  18]\n",
       "  [ 30  31  27]\n",
       "  [ 25  25  23]]\n",
       "\n",
       " [[  3   2   7]\n",
       "  [  4   3   8]\n",
       "  [  5   4   9]\n",
       "  ..., \n",
       "  [ 22  22  20]\n",
       "  [ 25  25  22]\n",
       "  [ 23  23  21]]\n",
       "\n",
       " ..., \n",
       " [[103  97  75]\n",
       "  [ 92  85  66]\n",
       "  [101  90  73]\n",
       "  ..., \n",
       "  [ 76  78  65]\n",
       "  [ 77  79  66]\n",
       "  [ 69  71  57]]\n",
       "\n",
       " [[105  98  79]\n",
       "  [108 101  83]\n",
       "  [106  98  82]\n",
       "  ..., \n",
       "  [ 69  71  60]\n",
       "  [ 79  81  68]\n",
       "  [ 81  83  70]]\n",
       "\n",
       " [[130 123 104]\n",
       "  [123 116  98]\n",
       "  [128 121 103]\n",
       "  ..., \n",
       "  [ 78  80  69]\n",
       "  [ 82  84  72]\n",
       "  [ 80  82  69]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow4_col1\" class=\"data row4 col1\" >2</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow4_col2\" class=\"data row4 col2\" >..\\datasets\\final\\D7\\c2\\20180219110143-Scissors-c1b76c29f77dc293.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow4_col3\" class=\"data row4 col3\" >D7</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row5\" >1404</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow5_col0\" class=\"data row5 col0\" >[[[ 88  30  22]\n",
       "  [ 88  26  21]\n",
       "  [ 93  30  25]\n",
       "  ..., \n",
       "  [ 27  26  27]\n",
       "  [ 24  25  24]\n",
       "  [ 23  26  22]]\n",
       "\n",
       " [[ 76  24  18]\n",
       "  [ 74  23  16]\n",
       "  [ 76  24  20]\n",
       "  ..., \n",
       "  [ 30  30  30]\n",
       "  [ 30  29  30]\n",
       "  [ 30  30  30]]\n",
       "\n",
       " [[ 61  20  11]\n",
       "  [ 66  25  15]\n",
       "  [ 65  26  15]\n",
       "  ..., \n",
       "  [ 26  26  25]\n",
       "  [ 24  25  24]\n",
       "  [ 29  29  29]]\n",
       "\n",
       " ..., \n",
       " [[221 205 181]\n",
       "  [222 206 180]\n",
       "  [223 207 182]\n",
       "  ..., \n",
       "  [196 176 152]\n",
       "  [196 176 152]\n",
       "  [196 176 152]]\n",
       "\n",
       " [[222 206 181]\n",
       "  [223 207 182]\n",
       "  [223 207 182]\n",
       "  ..., \n",
       "  [197 177 153]\n",
       "  [196 177 152]\n",
       "  [196 177 152]]\n",
       "\n",
       " [[222 206 180]\n",
       "  [222 206 182]\n",
       "  [222 206 181]\n",
       "  ..., \n",
       "  [197 177 153]\n",
       "  [196 176 152]\n",
       "  [196 176 152]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow5_col1\" class=\"data row5 col1\" >0</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow5_col2\" class=\"data row5 col2\" >..\\datasets\\final\\D7\\c0\\20180219133859-Rock-d10227e15e2074d5.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow5_col3\" class=\"data row5 col3\" >D7</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row6\" >1216</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow6_col0\" class=\"data row6 col0\" >[[[ 11  20  29]\n",
       "  [  9  18  27]\n",
       "  [ 11  21  30]\n",
       "  ..., \n",
       "  [163 166 157]\n",
       "  [160 167 156]\n",
       "  [159 167 156]]\n",
       "\n",
       " [[ 13  22  31]\n",
       "  [ 12  22  31]\n",
       "  [ 10  20  29]\n",
       "  ..., \n",
       "  [164 167 158]\n",
       "  [161 167 157]\n",
       "  [162 168 158]]\n",
       "\n",
       " [[ 12  21  30]\n",
       "  [ 12  21  30]\n",
       "  [ 10  20  29]\n",
       "  ..., \n",
       "  [163 166 157]\n",
       "  [162 165 156]\n",
       "  [163 166 157]]\n",
       "\n",
       " ..., \n",
       " [[ 64  23  33]\n",
       "  [ 65  22  32]\n",
       "  [ 64  22  35]\n",
       "  ..., \n",
       "  [151 152 156]\n",
       "  [152 153 156]\n",
       "  [151 152 154]]\n",
       "\n",
       " [[ 65  21  31]\n",
       "  [ 65  20  32]\n",
       "  [ 66  18  32]\n",
       "  ..., \n",
       "  [151 155 155]\n",
       "  [152 153 154]\n",
       "  [151 151 151]]\n",
       "\n",
       " [[ 67  21  32]\n",
       "  [ 66  20  33]\n",
       "  [ 66  19  32]\n",
       "  ..., \n",
       "  [148 152 151]\n",
       "  [149 151 151]\n",
       "  [148 150 150]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow6_col1\" class=\"data row6 col1\" >2</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow6_col2\" class=\"data row6 col2\" >..\\datasets\\final\\D3\\c2\\20170705_112257.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow6_col3\" class=\"data row6 col3\" >D3</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row7\" >313</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow7_col0\" class=\"data row7 col0\" >[[[171 143  95]\n",
       "  [172 144  96]\n",
       "  [171 143  95]\n",
       "  ..., \n",
       "  [124  78  16]\n",
       "  [124  74  12]\n",
       "  [129  79  16]]\n",
       "\n",
       " [[170 142  94]\n",
       "  [171 143  95]\n",
       "  [171 143  95]\n",
       "  ..., \n",
       "  [129  83  21]\n",
       "  [125  77  14]\n",
       "  [124  76  12]]\n",
       "\n",
       " [[172 144  96]\n",
       "  [172 144  96]\n",
       "  [172 144  96]\n",
       "  ..., \n",
       "  [128  83  18]\n",
       "  [130  83  19]\n",
       "  [130  82  18]]\n",
       "\n",
       " ..., \n",
       " [[174 146  98]\n",
       "  [175 147  99]\n",
       "  [177 149 101]\n",
       "  ..., \n",
       "  [165 138  95]\n",
       "  [166 139  96]\n",
       "  [166 139  96]]\n",
       "\n",
       " [[176 148 101]\n",
       "  [176 148 101]\n",
       "  [176 148 100]\n",
       "  ..., \n",
       "  [164 137  94]\n",
       "  [165 138  95]\n",
       "  [164 137  94]]\n",
       "\n",
       " [[176 148 101]\n",
       "  [176 148 101]\n",
       "  [176 148 100]\n",
       "  ..., \n",
       "  [164 137  94]\n",
       "  [165 138  95]\n",
       "  [164 137  94]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow7_col1\" class=\"data row7 col1\" >0</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow7_col2\" class=\"data row7 col2\" >..\\datasets\\final\\D6\\c0\\IMG_20180119_102243.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow7_col3\" class=\"data row7 col3\" >D6</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row8\" >877</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow8_col0\" class=\"data row8 col0\" >[[[  1   1   1]\n",
       "  [  2   2   2]\n",
       "  [  0   0   0]\n",
       "  ..., \n",
       "  [107 116 111]\n",
       "  [115 122 117]\n",
       "  [110 116 112]]\n",
       "\n",
       " [[  1   1   1]\n",
       "  [  1   1   1]\n",
       "  [  2   2   2]\n",
       "  ..., \n",
       "  [106 114 110]\n",
       "  [112 119 115]\n",
       "  [114 120 116]]\n",
       "\n",
       " [[  3   3   3]\n",
       "  [  0   0   0]\n",
       "  [  1   1   1]\n",
       "  ..., \n",
       "  [111 117 115]\n",
       "  [115 121 117]\n",
       "  [114 119 115]]\n",
       "\n",
       " ..., \n",
       " [[ 98  87  75]\n",
       "  [116 113 105]\n",
       "  [115 117 110]\n",
       "  ..., \n",
       "  [107 109 108]\n",
       "  [105 108 108]\n",
       "  [106 110 109]]\n",
       "\n",
       " [[102  96  87]\n",
       "  [117 115 107]\n",
       "  [115 117 109]\n",
       "  ..., \n",
       "  [109 113 109]\n",
       "  [110 113 109]\n",
       "  [110 112 108]]\n",
       "\n",
       " [[109 105  96]\n",
       "  [116 114 107]\n",
       "  [115 116 108]\n",
       "  ..., \n",
       "  [108 113 107]\n",
       "  [109 111 106]\n",
       "  [108 110 105]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow8_col1\" class=\"data row8 col1\" >2</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow8_col2\" class=\"data row8 col2\" >..\\datasets\\final\\D5\\c2\\20170914_115810.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow8_col3\" class=\"data row8 col3\" >D5</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bf\" class=\"row_heading level0 row9\" >966</th> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow9_col0\" class=\"data row9 col0\" >[[[190 179 170]\n",
       "  [182 179 167]\n",
       "  [193 179 173]\n",
       "  ..., \n",
       "  [ 31  45  54]\n",
       "  [ 35  47  56]\n",
       "  [ 32  43  55]]\n",
       "\n",
       " [[142 129 120]\n",
       "  [175 158 150]\n",
       "  [139 115 110]\n",
       "  ..., \n",
       "  [ 34  45  57]\n",
       "  [ 40  54  64]\n",
       "  [ 31  43  53]]\n",
       "\n",
       " [[184 178 168]\n",
       "  [ 95  82  72]\n",
       "  [148 118 113]\n",
       "  ..., \n",
       "  [ 30  43  55]\n",
       "  [ 35  47  59]\n",
       "  [ 35  46  60]]\n",
       "\n",
       " ..., \n",
       " [[114 120 122]\n",
       "  [129 133 132]\n",
       "  [143 143 141]\n",
       "  ..., \n",
       "  [155 149 141]\n",
       "  [171 167 159]\n",
       "  [163 156 148]]\n",
       "\n",
       " [[182 190 192]\n",
       "  [ 98 104 106]\n",
       "  [142 143 141]\n",
       "  ..., \n",
       "  [166 160 153]\n",
       "  [144 136 131]\n",
       "  [165 157 150]]\n",
       "\n",
       " [[210 215 215]\n",
       "  [205 213 215]\n",
       "  [ 53  60  62]\n",
       "  ..., \n",
       "  [154 149 143]\n",
       "  [163 156 149]\n",
       "  [184 176 171]]]</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow9_col1\" class=\"data row9 col1\" >1</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow9_col2\" class=\"data row9 col2\" >..\\datasets\\final\\D7\\c1\\20180219134209-Paper-8ec1afbbea993244.jpg</td> \n",
       "        <td id=\"T_9c34f134_2c25_11e8_93d0_c159740c32bfrow9_col3\" class=\"data row9 col3\" >D7</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x203009460b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample(n=10)[[\"image\",\"label\",\"file\",\"dn\"]].style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optionally, we can quickly scroll through the images in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer=skimage.viewer.CollectionViewer([r[1][\"image\"] for r in dataset.iterrows()])\n",
    "viewer.show()\n",
    "# Note: you have to close the window to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3: Prepare training and testing sets\n",
    "\n",
    "How should we split training and testing data?  The code below implements a few options (run only one of the cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option one (hard): use all samples from dataset named \"testing\"\n",
    "# which contains some images taken in the same days as D1--D4, but not contained in these dirs.\n",
    "te_mask = dataset[\"dn\"]==\"testing\"\n",
    "dataset_te=dataset[te_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option two (hard): test on all samples from one specific dataset\n",
    "te_mask = dataset[\"dn\"]==\"D2\"\n",
    "dataset_te=dataset[te_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# In any case, training samples are all other samples\n",
    "dataset_tr=dataset.loc[dataset.index.difference(dataset_te.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Training images</th>\n",
       "      <th># Testing images</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rock</th>\n",
       "      <td>543</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper</th>\n",
       "      <td>504</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scissors</th>\n",
       "      <td>578</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            # Training images  # Testing images\n",
       "Class name                                     \n",
       "rock                      543                69\n",
       "paper                     504                71\n",
       "scissors                  578                63"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a summary of how many training and testing images we have sampled\n",
    "import collections\n",
    "pd.DataFrame(index=[0,1,2],data=collections.OrderedDict((\n",
    "    (\"Class name\",           names),\n",
    "    (\"# Training images\", dataset_tr[\"label\"].value_counts()),\n",
    "    (\"# Testing images\",  dataset_te[\"label\"].value_counts())))).set_index(\"Class name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a710651b61641858738c0218f8e69ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.imgplotList>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "examples=list(dataset_te[\"image\"])\n",
    "interact(\n",
    "    imgplotList, \n",
    "    i=widgets.IntSlider(min=0,max=len(examples)-1, step=1, value=0,continuous_update=True), \n",
    "    data=fixed(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 4: define what we feed to the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "im = dataset_tr.sample(1).iloc[0][\"image\"]\n",
    "print(im.shape, im.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Take image and resize to a specified size\n",
    "def transform_simple(im,sz):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        imr = skimage.transform.resize(im, (sz,sz))\n",
    "    return imr\n",
    "\n",
    "transform = transform_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Take image and resize to a specified size, after applying data augmentation\n",
    "def transform_complex(im,sz):\n",
    "    if(np.random.rand()<0.5):\n",
    "        im=np.fliplr(im)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        tf1 = skimage.transform.SimilarityTransform(scale = 1 / im.shape[0])\n",
    "        tf2 = skimage.transform.SimilarityTransform(translation=[-0.5, -0.5])\n",
    "        tf3 = skimage.transform.SimilarityTransform(rotation=np.deg2rad(np.random.uniform(0,360)))\n",
    "        tf4 = skimage.transform.SimilarityTransform(scale=np.random.uniform(1,1.6))\n",
    "        tf5 = skimage.transform.SimilarityTransform(translation=np.array([0.5, 0.5])+np.random.uniform(-0.1,0.1,size=2))\n",
    "        tf6 = skimage.transform.SimilarityTransform(scale=sz)\n",
    "        imr = skimage.transform.warp(im, (tf1+(tf2+(tf3+(tf4+(tf5+tf6))))).inverse, output_shape=(sz,sz),mode=\"edge\")\n",
    "        imr = imr*np.random.uniform(0.9,1.1,size=(1,1,3))\n",
    "        imr = np.clip(imr,0,1)\n",
    "    return imr\n",
    "\n",
    "transform = transform_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f93f0d6471d4de68db6426e9c61c07a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvYAAAF1CAYAAACDLa7LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7AEAIEDYAwBAwH+Vz2T80QX2IAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2030d3c81d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The resolution challenge\n",
    "@interact(sz = widgets.IntSlider(min=2,max=100),\n",
    "          seed = widgets.IntSlider(min=0,max=100),\n",
    "          reveal = widgets.widgets.ToggleButton(value=False,description='Reveal'))\n",
    "def f(sz,seed,reveal):\n",
    "    fig,axs = plt.subplots(nrows = 2, ncols = 5,figsize=(6,3),dpi=150)\n",
    "    ims = dataset_tr.sample(len(axs.flatten()), random_state=sz*100+seed)\n",
    "    for ax,(_,row) in zip(axs.flatten(),ims.iterrows()):\n",
    "        ax.imshow(transform_simple(row[\"image\"],sz))\n",
    "        ax.axis(\"off\")\n",
    "        if(reveal):\n",
    "            ax.set_title(names[row[\"label\"]])\n",
    "    #fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def sample(df,sz):\n",
    "    r=df.sample(n=1)\n",
    "    l=r[\"label\"].iloc[0]\n",
    "    im=r[\"image\"].iloc[0]\n",
    "    im=transform(im,sz)\n",
    "    return im,l\n",
    "\n",
    "def mkbatch(df,N,sz):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(N):\n",
    "        im,l=sample(df,sz)\n",
    "        X.append(im)\n",
    "        y.append(l)\n",
    "    X=np.array(X).astype('float32')\n",
    "    y=np.array(y)\n",
    "    y=keras.utils.np_utils.to_categorical(y,3)\n",
    "    return X,y\n",
    "\n",
    "def generator(df,batch_size,sz):\n",
    "    while True:\n",
    "        X,y = mkbatch(df,batch_size,sz)\n",
    "        yield (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = mkbatch(dataset_tr,20,32)\n",
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ab1cf88d4848bc8820510e697e11ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.imgplotList>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize 100 images from our input dataset\n",
    "examples = list(mkbatch(dataset_tr,100,32)[0])\n",
    "interact(imgplotList, i=widgets.IntSlider(min=0, max=len(examples)-1, step=1, value=0,continuous_update=False), data=fixed(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f6e010a54846b4ad3727fbcde2cc18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.imgplotList>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize 100 variations from our first input image (makes sense only if transform==transform_complex, i.e. if we are using data augmentation)\n",
    "examples = list(mkbatch(dataset_tr.iloc[[0]],100,32)[0])\n",
    "interact(imgplotList, i=widgets.IntSlider(min=0, max=len(examples)-1, step=1, value=0,continuous_update=False), data=fixed(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 5: build and train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras: Deep Learning library for Theano and TensorFlow\n",
    "import keras\n",
    "from keras.utils  import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dropout\n",
    "\n",
    "# NN settings\n",
    "patchsize          = 32\n",
    "batch_size         = 32\n",
    "pool_size          = (2,2) # size of pooling area for max pooling\n",
    "kernel_size        = (3,3) # convolution kernel size\n",
    "\n",
    "def makeModel(nb_filters):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(nb_filters, kernel_size, input_shape=(patchsize,patchsize,3), padding = \"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = pool_size))\n",
    "    model.add(Conv2D(nb_filters*2, kernel_size, padding = \"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = pool_size))\n",
    "    model.add(Conv2D(nb_filters*4, kernel_size, padding = \"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = pool_size))\n",
    "    model.add(AveragePooling2D(pool_size = pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128)) # generate a fully connected layer wiht 128 outputs (arbitrary value)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3)) # output layer\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    ## compile! network\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       3584      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,741,571\n",
      "Trainable params: 1,741,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "makeModel(128).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Build a set of 1000 testing instances taken from the testing dataset.\n",
    "\n",
    "Note: \"testing\" in this case is synonym with \"validation\" and \"evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_test,y_test) = mkbatch(dataset_te, 1000, patchsize)\n",
    "\n",
    "# Prepare the logs directory, if it does not exist\n",
    "(pathlib.Path(\".\")/\"logs\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "While the network trains, we can monitor training loss/accuracy and testing loss/accuracy using tensorboard at http://0.0.0.0:6006\n",
    "\n",
    "You may need to launch tensorboard first if it's not already running, by executing\n",
    "\n",
    "`tensorboard --logdir=logs`\n",
    "\n",
    "in a shell with the current working directory.  Check that you are within the proper conda environment, if applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "50/50 [==============================] - ETA: 28s - loss: 1.0867 - acc: 0.40 - ETA: 20s - loss: 1.0940 - acc: 0.37 - ETA: 19s - loss: 1.0771 - acc: 0.41 - ETA: 18s - loss: 1.0865 - acc: 0.39 - ETA: 17s - loss: 1.0792 - acc: 0.42 - ETA: 16s - loss: 1.0821 - acc: 0.42 - ETA: 16s - loss: 1.0749 - acc: 0.42 - ETA: 15s - loss: 1.0898 - acc: 0.42 - ETA: 14s - loss: 1.0945 - acc: 0.41 - ETA: 14s - loss: 1.0989 - acc: 0.40 - ETA: 13s - loss: 1.0975 - acc: 0.40 - ETA: 13s - loss: 1.0945 - acc: 0.41 - ETA: 12s - loss: 1.0930 - acc: 0.41 - ETA: 12s - loss: 1.0936 - acc: 0.41 - ETA: 11s - loss: 1.0957 - acc: 0.40 - ETA: 11s - loss: 1.0958 - acc: 0.40 - ETA: 10s - loss: 1.0963 - acc: 0.40 - ETA: 10s - loss: 1.0973 - acc: 0.39 - ETA: 9s - loss: 1.0969 - acc: 0.3964 - ETA: 9s - loss: 1.0983 - acc: 0.389 - ETA: 8s - loss: 1.0991 - acc: 0.381 - ETA: 8s - loss: 1.0994 - acc: 0.369 - ETA: 7s - loss: 1.0991 - acc: 0.369 - ETA: 7s - loss: 1.0989 - acc: 0.365 - ETA: 7s - loss: 1.0991 - acc: 0.362 - ETA: 6s - loss: 1.0988 - acc: 0.365 - ETA: 6s - loss: 1.0987 - acc: 0.366 - ETA: 6s - loss: 1.0984 - acc: 0.367 - ETA: 5s - loss: 1.0984 - acc: 0.363 - ETA: 5s - loss: 1.0984 - acc: 0.360 - ETA: 5s - loss: 1.0985 - acc: 0.354 - ETA: 4s - loss: 1.0987 - acc: 0.353 - ETA: 4s - loss: 1.0987 - acc: 0.355 - ETA: 4s - loss: 1.0987 - acc: 0.352 - ETA: 3s - loss: 1.0986 - acc: 0.350 - ETA: 3s - loss: 1.0987 - acc: 0.349 - ETA: 3s - loss: 1.0988 - acc: 0.347 - ETA: 3s - loss: 1.0989 - acc: 0.344 - ETA: 2s - loss: 1.0989 - acc: 0.342 - ETA: 2s - loss: 1.0988 - acc: 0.345 - ETA: 2s - loss: 1.0988 - acc: 0.346 - ETA: 2s - loss: 1.0987 - acc: 0.346 - ETA: 1s - loss: 1.0986 - acc: 0.348 - ETA: 1s - loss: 1.0986 - acc: 0.347 - ETA: 1s - loss: 1.0986 - acc: 0.347 - ETA: 1s - loss: 1.0986 - acc: 0.347 - ETA: 0s - loss: 1.0986 - acc: 0.346 - ETA: 0s - loss: 1.0987 - acc: 0.344 - ETA: 0s - loss: 1.0988 - acc: 0.342 - 14s - loss: 1.0988 - acc: 0.3419 - val_loss: 1.0977 - val_acc: 0.3390\n",
      "Epoch 2/6\n",
      "50/50 [==============================] - ETA: 9s - loss: 1.0950 - acc: 0.375 - ETA: 8s - loss: 1.0974 - acc: 0.296 - ETA: 8s - loss: 1.0982 - acc: 0.333 - ETA: 8s - loss: 1.0974 - acc: 0.359 - ETA: 8s - loss: 1.0970 - acc: 0.356 - ETA: 8s - loss: 1.0979 - acc: 0.343 - ETA: 8s - loss: 1.0971 - acc: 0.357 - ETA: 8s - loss: 1.0972 - acc: 0.363 - ETA: 7s - loss: 1.0970 - acc: 0.361 - ETA: 7s - loss: 1.0972 - acc: 0.359 - ETA: 7s - loss: 1.0967 - acc: 0.355 - ETA: 7s - loss: 1.0969 - acc: 0.354 - ETA: 7s - loss: 1.0972 - acc: 0.348 - ETA: 7s - loss: 1.0973 - acc: 0.350 - ETA: 7s - loss: 1.0966 - acc: 0.364 - ETA: 7s - loss: 1.0968 - acc: 0.365 - ETA: 7s - loss: 1.0972 - acc: 0.365 - ETA: 7s - loss: 1.0968 - acc: 0.369 - ETA: 7s - loss: 1.0972 - acc: 0.365 - ETA: 7s - loss: 1.0977 - acc: 0.357 - ETA: 7s - loss: 1.0976 - acc: 0.357 - ETA: 6s - loss: 1.0978 - acc: 0.356 - ETA: 6s - loss: 1.0981 - acc: 0.351 - ETA: 6s - loss: 1.0986 - acc: 0.345 - ETA: 6s - loss: 1.0989 - acc: 0.340 - ETA: 5s - loss: 1.0990 - acc: 0.338 - ETA: 5s - loss: 1.0987 - acc: 0.341 - ETA: 5s - loss: 1.0987 - acc: 0.339 - ETA: 5s - loss: 1.0987 - acc: 0.341 - ETA: 4s - loss: 1.0985 - acc: 0.341 - ETA: 4s - loss: 1.0986 - acc: 0.342 - ETA: 4s - loss: 1.0987 - acc: 0.341 - ETA: 4s - loss: 1.0985 - acc: 0.340 - ETA: 4s - loss: 1.0985 - acc: 0.341 - ETA: 3s - loss: 1.0986 - acc: 0.340 - ETA: 3s - loss: 1.0983 - acc: 0.342 - ETA: 3s - loss: 1.0985 - acc: 0.339 - ETA: 3s - loss: 1.0984 - acc: 0.340 - ETA: 2s - loss: 1.0984 - acc: 0.339 - ETA: 2s - loss: 1.0983 - acc: 0.340 - ETA: 2s - loss: 1.0983 - acc: 0.342 - ETA: 2s - loss: 1.0985 - acc: 0.340 - ETA: 1s - loss: 1.0984 - acc: 0.342 - ETA: 1s - loss: 1.0985 - acc: 0.341 - ETA: 1s - loss: 1.0984 - acc: 0.343 - ETA: 1s - loss: 1.0983 - acc: 0.345 - ETA: 0s - loss: 1.0980 - acc: 0.347 - ETA: 0s - loss: 1.0980 - acc: 0.348 - ETA: 0s - loss: 1.0982 - acc: 0.345 - 15s - loss: 1.0982 - acc: 0.3444 - val_loss: 1.0984 - val_acc: 0.3330\n",
      "Epoch 3/6\n",
      "50/50 [==============================] - ETA: 8s - loss: 1.1166 - acc: 0.250 - ETA: 10s - loss: 1.1025 - acc: 0.34 - ETA: 10s - loss: 1.1025 - acc: 0.33 - ETA: 10s - loss: 1.1037 - acc: 0.32 - ETA: 10s - loss: 1.1007 - acc: 0.34 - ETA: 9s - loss: 1.1003 - acc: 0.3385 - ETA: 9s - loss: 1.1001 - acc: 0.334 - ETA: 9s - loss: 1.1001 - acc: 0.339 - ETA: 9s - loss: 1.0984 - acc: 0.347 - ETA: 8s - loss: 1.0982 - acc: 0.350 - ETA: 8s - loss: 1.1002 - acc: 0.329 - ETA: 8s - loss: 1.0999 - acc: 0.333 - ETA: 8s - loss: 1.0997 - acc: 0.336 - ETA: 8s - loss: 1.0997 - acc: 0.339 - ETA: 7s - loss: 1.0998 - acc: 0.341 - ETA: 7s - loss: 1.0998 - acc: 0.341 - ETA: 7s - loss: 1.0998 - acc: 0.336 - ETA: 7s - loss: 1.0992 - acc: 0.343 - ETA: 7s - loss: 1.0991 - acc: 0.342 - ETA: 7s - loss: 1.0993 - acc: 0.337 - ETA: 7s - loss: 1.0989 - acc: 0.340 - ETA: 6s - loss: 1.0989 - acc: 0.343 - ETA: 6s - loss: 1.0986 - acc: 0.345 - ETA: 6s - loss: 1.0986 - acc: 0.342 - ETA: 6s - loss: 1.0983 - acc: 0.342 - ETA: 5s - loss: 1.0982 - acc: 0.342 - ETA: 5s - loss: 1.0979 - acc: 0.340 - ETA: 5s - loss: 1.0979 - acc: 0.341 - ETA: 4s - loss: 1.0974 - acc: 0.345 - ETA: 4s - loss: 1.0976 - acc: 0.344 - ETA: 4s - loss: 1.0977 - acc: 0.346 - ETA: 4s - loss: 1.0974 - acc: 0.347 - ETA: 3s - loss: 1.0975 - acc: 0.346 - ETA: 3s - loss: 1.0975 - acc: 0.346 - ETA: 3s - loss: 1.0969 - acc: 0.350 - ETA: 3s - loss: 1.0972 - acc: 0.347 - ETA: 3s - loss: 1.0973 - acc: 0.345 - ETA: 2s - loss: 1.0974 - acc: 0.347 - ETA: 2s - loss: 1.0982 - acc: 0.349 - ETA: 2s - loss: 1.0980 - acc: 0.350 - ETA: 2s - loss: 1.0978 - acc: 0.350 - ETA: 1s - loss: 1.0971 - acc: 0.354 - ETA: 1s - loss: 1.0984 - acc: 0.351 - ETA: 1s - loss: 1.0980 - acc: 0.350 - ETA: 1s - loss: 1.0971 - acc: 0.355 - ETA: 0s - loss: 1.0973 - acc: 0.356 - ETA: 0s - loss: 1.0976 - acc: 0.355 - ETA: 0s - loss: 1.0968 - acc: 0.357 - ETA: 0s - loss: 1.0967 - acc: 0.355 - 13s - loss: 1.0966 - acc: 0.3563 - val_loss: 1.1032 - val_acc: 0.3330\n",
      "Epoch 4/6\n",
      "50/50 [==============================] - ETA: 8s - loss: 1.1027 - acc: 0.281 - ETA: 7s - loss: 1.0944 - acc: 0.343 - ETA: 8s - loss: 1.0983 - acc: 0.322 - ETA: 7s - loss: 1.1010 - acc: 0.335 - ETA: 7s - loss: 1.1049 - acc: 0.306 - ETA: 7s - loss: 1.0982 - acc: 0.328 - ETA: 7s - loss: 1.0980 - acc: 0.321 - ETA: 6s - loss: 1.0990 - acc: 0.312 - ETA: 6s - loss: 1.0982 - acc: 0.309 - ETA: 6s - loss: 1.0980 - acc: 0.321 - ETA: 6s - loss: 1.0987 - acc: 0.326 - ETA: 6s - loss: 1.0975 - acc: 0.328 - ETA: 6s - loss: 1.0977 - acc: 0.334 - ETA: 6s - loss: 1.0986 - acc: 0.321 - ETA: 5s - loss: 1.0985 - acc: 0.322 - ETA: 5s - loss: 1.0988 - acc: 0.314 - ETA: 5s - loss: 1.0985 - acc: 0.319 - ETA: 5s - loss: 1.0984 - acc: 0.319 - ETA: 5s - loss: 1.0977 - acc: 0.328 - ETA: 5s - loss: 1.0977 - acc: 0.331 - ETA: 5s - loss: 1.0968 - acc: 0.342 - ETA: 4s - loss: 1.0971 - acc: 0.339 - ETA: 4s - loss: 1.0963 - acc: 0.349 - ETA: 4s - loss: 1.0963 - acc: 0.350 - ETA: 4s - loss: 1.0960 - acc: 0.347 - ETA: 4s - loss: 1.0958 - acc: 0.348 - ETA: 4s - loss: 1.0965 - acc: 0.341 - ETA: 4s - loss: 1.0962 - acc: 0.346 - ETA: 4s - loss: 1.0964 - acc: 0.345 - ETA: 3s - loss: 1.0973 - acc: 0.343 - ETA: 3s - loss: 1.0969 - acc: 0.345 - ETA: 3s - loss: 1.0969 - acc: 0.346 - ETA: 3s - loss: 1.0966 - acc: 0.347 - ETA: 3s - loss: 1.0967 - acc: 0.347 - ETA: 3s - loss: 1.0966 - acc: 0.349 - ETA: 2s - loss: 1.0967 - acc: 0.344 - ETA: 2s - loss: 1.0964 - acc: 0.342 - ETA: 2s - loss: 1.0963 - acc: 0.343 - ETA: 2s - loss: 1.0963 - acc: 0.342 - ETA: 2s - loss: 1.0968 - acc: 0.343 - ETA: 1s - loss: 1.0961 - acc: 0.346 - ETA: 1s - loss: 1.0956 - acc: 0.347 - ETA: 1s - loss: 1.0956 - acc: 0.348 - ETA: 1s - loss: 1.0958 - acc: 0.346 - ETA: 1s - loss: 1.0959 - acc: 0.345 - ETA: 0s - loss: 1.0961 - acc: 0.343 - ETA: 0s - loss: 1.0960 - acc: 0.342 - ETA: 0s - loss: 1.0958 - acc: 0.345 - ETA: 0s - loss: 1.0957 - acc: 0.344 - 11s - loss: 1.0956 - acc: 0.3444 - val_loss: 1.0951 - val_acc: 0.3540\n",
      "Epoch 5/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 7s - loss: 1.0996 - acc: 0.312 - ETA: 8s - loss: 1.1075 - acc: 0.296 - ETA: 7s - loss: 1.1000 - acc: 0.270 - ETA: 7s - loss: 1.0992 - acc: 0.289 - ETA: 7s - loss: 1.0913 - acc: 0.331 - ETA: 7s - loss: 1.0904 - acc: 0.343 - ETA: 6s - loss: 1.0854 - acc: 0.361 - ETA: 6s - loss: 1.0812 - acc: 0.351 - ETA: 6s - loss: 1.0785 - acc: 0.357 - ETA: 6s - loss: 1.0798 - acc: 0.359 - ETA: 6s - loss: 1.0872 - acc: 0.366 - ETA: 6s - loss: 1.0967 - acc: 0.359 - ETA: 6s - loss: 1.0939 - acc: 0.358 - ETA: 5s - loss: 1.0927 - acc: 0.377 - ETA: 5s - loss: 1.0946 - acc: 0.364 - ETA: 5s - loss: 1.0938 - acc: 0.371 - ETA: 5s - loss: 1.0939 - acc: 0.369 - ETA: 5s - loss: 1.0947 - acc: 0.364 - ETA: 5s - loss: 1.0940 - acc: 0.370 - ETA: 5s - loss: 1.0949 - acc: 0.359 - ETA: 4s - loss: 1.0951 - acc: 0.354 - ETA: 4s - loss: 1.0951 - acc: 0.352 - ETA: 4s - loss: 1.0954 - acc: 0.347 - ETA: 4s - loss: 1.0953 - acc: 0.349 - ETA: 4s - loss: 1.0956 - acc: 0.348 - ETA: 4s - loss: 1.0954 - acc: 0.351 - ETA: 4s - loss: 1.0950 - acc: 0.356 - ETA: 4s - loss: 1.0954 - acc: 0.352 - ETA: 3s - loss: 1.0951 - acc: 0.353 - ETA: 3s - loss: 1.0954 - acc: 0.350 - ETA: 3s - loss: 1.0953 - acc: 0.345 - ETA: 3s - loss: 1.0951 - acc: 0.345 - ETA: 3s - loss: 1.0948 - acc: 0.345 - ETA: 2s - loss: 1.0951 - acc: 0.343 - ETA: 2s - loss: 1.0951 - acc: 0.344 - ETA: 2s - loss: 1.0951 - acc: 0.345 - ETA: 2s - loss: 1.0950 - acc: 0.345 - ETA: 2s - loss: 1.0948 - acc: 0.345 - ETA: 2s - loss: 1.0951 - acc: 0.347 - ETA: 1s - loss: 1.0951 - acc: 0.345 - ETA: 1s - loss: 1.0953 - acc: 0.343 - ETA: 1s - loss: 1.0947 - acc: 0.346 - ETA: 1s - loss: 1.0954 - acc: 0.343 - ETA: 1s - loss: 1.0959 - acc: 0.345 - ETA: 0s - loss: 1.0959 - acc: 0.347 - ETA: 0s - loss: 1.0960 - acc: 0.347 - ETA: 0s - loss: 1.0955 - acc: 0.347 - ETA: 0s - loss: 1.0956 - acc: 0.347 - ETA: 0s - loss: 1.0960 - acc: 0.346 - 11s - loss: 1.0955 - acc: 0.3488 - val_loss: 1.0995 - val_acc: 0.3330\n",
      "Epoch 6/6\n",
      "50/50 [==============================] - ETA: 8s - loss: 1.1008 - acc: 0.437 - ETA: 8s - loss: 1.0977 - acc: 0.359 - ETA: 8s - loss: 1.0994 - acc: 0.395 - ETA: 7s - loss: 1.1018 - acc: 0.390 - ETA: 7s - loss: 1.1022 - acc: 0.356 - ETA: 7s - loss: 1.0984 - acc: 0.375 - ETA: 7s - loss: 1.0977 - acc: 0.388 - ETA: 7s - loss: 1.0962 - acc: 0.402 - ETA: 6s - loss: 1.0973 - acc: 0.378 - ETA: 6s - loss: 1.0978 - acc: 0.378 - ETA: 6s - loss: 1.0978 - acc: 0.377 - ETA: 6s - loss: 1.0971 - acc: 0.375 - ETA: 6s - loss: 1.0965 - acc: 0.375 - ETA: 6s - loss: 1.0950 - acc: 0.377 - ETA: 5s - loss: 1.0946 - acc: 0.377 - ETA: 5s - loss: 1.0929 - acc: 0.378 - ETA: 5s - loss: 1.0918 - acc: 0.378 - ETA: 5s - loss: 1.0907 - acc: 0.375 - ETA: 5s - loss: 1.0932 - acc: 0.373 - ETA: 5s - loss: 1.0911 - acc: 0.370 - ETA: 5s - loss: 1.0916 - acc: 0.369 - ETA: 4s - loss: 1.0906 - acc: 0.370 - ETA: 4s - loss: 1.0934 - acc: 0.369 - ETA: 4s - loss: 1.0927 - acc: 0.371 - ETA: 4s - loss: 1.0911 - acc: 0.375 - ETA: 4s - loss: 1.0922 - acc: 0.373 - ETA: 4s - loss: 1.0931 - acc: 0.372 - ETA: 4s - loss: 1.0942 - acc: 0.368 - ETA: 3s - loss: 1.0937 - acc: 0.371 - ETA: 3s - loss: 1.0945 - acc: 0.370 - ETA: 3s - loss: 1.0935 - acc: 0.374 - ETA: 3s - loss: 1.0934 - acc: 0.373 - ETA: 3s - loss: 1.0928 - acc: 0.372 - ETA: 3s - loss: 1.0941 - acc: 0.362 - ETA: 2s - loss: 1.0941 - acc: 0.360 - ETA: 2s - loss: 1.0938 - acc: 0.365 - ETA: 2s - loss: 1.0929 - acc: 0.368 - ETA: 2s - loss: 1.0935 - acc: 0.366 - ETA: 2s - loss: 1.0938 - acc: 0.363 - ETA: 1s - loss: 1.0937 - acc: 0.363 - ETA: 1s - loss: 1.0939 - acc: 0.362 - ETA: 1s - loss: 1.0948 - acc: 0.359 - ETA: 1s - loss: 1.0946 - acc: 0.361 - ETA: 1s - loss: 1.0945 - acc: 0.365 - ETA: 0s - loss: 1.0949 - acc: 0.363 - ETA: 0s - loss: 1.0949 - acc: 0.365 - ETA: 0s - loss: 1.0946 - acc: 0.367 - ETA: 0s - loss: 1.0943 - acc: 0.369 - ETA: 0s - loss: 1.0943 - acc: 0.368 - 11s - loss: 1.0930 - acc: 0.3700 - val_loss: 1.0934 - val_acc: 0.3560\n"
     ]
    }
   ],
   "source": [
    "modelid = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=50),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='model_checkpoint_best_{}.h5'.format(modelid),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True),\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='./logs/'+modelid,\n",
    "        histogram_freq=0, write_graph=False, write_images=False)\n",
    "]\n",
    "\n",
    "model = makeModel(32)\n",
    "history=model.fit_generator(\n",
    "                    generator(dataset_tr, batch_size, patchsize),\n",
    "                    steps_per_epoch=50, \n",
    "                    epochs=6, \n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test,y_test),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After training our model, we can save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelname = \"input32\"\n",
    "\n",
    "# Save model to a file\n",
    "keras.models.save_model(model,\"{}.model\".format(modelname))\n",
    "\n",
    "# Also save the testing dataset (may be large) so we can pick up from here later \n",
    "dataset_te.to_pickle(\"{}.testingdata.pickle\".format(modelname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you have time and want to experiment, you may train many networks exploring the parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 1)         28        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 2)         20        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16, 16, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 4)           76        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 8, 8, 4)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 4)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 2, 2, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,687\n",
      "Trainable params: 2,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "2687\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - ETA: 12s - loss: 1.0961 - acc: 0.34 - ETA: 8s - loss: 1.0933 - acc: 0.3594 - ETA: 8s - loss: 1.0984 - acc: 0.333 - ETA: 8s - loss: 1.0993 - acc: 0.328 - ETA: 8s - loss: 1.0976 - acc: 0.350 - ETA: 8s - loss: 1.0976 - acc: 0.333 - ETA: 7s - loss: 1.0982 - acc: 0.321 - ETA: 7s - loss: 1.0974 - acc: 0.351 - ETA: 7s - loss: 1.0975 - acc: 0.347 - ETA: 7s - loss: 1.0975 - acc: 0.356 - ETA: 7s - loss: 1.0970 - acc: 0.363 - ETA: 6s - loss: 1.0973 - acc: 0.359 - ETA: 6s - loss: 1.0974 - acc: 0.358 - ETA: 6s - loss: 1.0974 - acc: 0.363 - ETA: 6s - loss: 1.0974 - acc: 0.360 - ETA: 6s - loss: 1.0971 - acc: 0.363 - ETA: 5s - loss: 1.0971 - acc: 0.364 - ETA: 5s - loss: 1.0974 - acc: 0.361 - ETA: 5s - loss: 1.0976 - acc: 0.356 - ETA: 5s - loss: 1.0975 - acc: 0.357 - ETA: 5s - loss: 1.0978 - acc: 0.357 - ETA: 4s - loss: 1.0977 - acc: 0.356 - ETA: 4s - loss: 1.0980 - acc: 0.353 - ETA: 4s - loss: 1.0984 - acc: 0.351 - ETA: 4s - loss: 1.0978 - acc: 0.357 - ETA: 3s - loss: 1.0979 - acc: 0.355 - ETA: 3s - loss: 1.0975 - acc: 0.358 - ETA: 3s - loss: 1.0976 - acc: 0.357 - ETA: 3s - loss: 1.0972 - acc: 0.359 - ETA: 3s - loss: 1.0970 - acc: 0.359 - ETA: 3s - loss: 1.0971 - acc: 0.356 - ETA: 2s - loss: 1.0965 - acc: 0.362 - ETA: 2s - loss: 1.0969 - acc: 0.358 - ETA: 2s - loss: 1.0967 - acc: 0.361 - ETA: 2s - loss: 1.0964 - acc: 0.364 - ETA: 2s - loss: 1.0961 - acc: 0.366 - ETA: 2s - loss: 1.0964 - acc: 0.365 - ETA: 1s - loss: 1.0967 - acc: 0.362 - ETA: 1s - loss: 1.0969 - acc: 0.363 - ETA: 1s - loss: 1.0971 - acc: 0.361 - ETA: 1s - loss: 1.0970 - acc: 0.362 - ETA: 1s - loss: 1.0972 - acc: 0.362 - ETA: 1s - loss: 1.0971 - acc: 0.361 - ETA: 0s - loss: 1.0967 - acc: 0.365 - ETA: 0s - loss: 1.0964 - acc: 0.366 - ETA: 0s - loss: 1.0963 - acc: 0.366 - ETA: 0s - loss: 1.0968 - acc: 0.363 - ETA: 0s - loss: 1.0969 - acc: 0.363 - ETA: 0s - loss: 1.0967 - acc: 0.366 - 8s - loss: 1.0968 - acc: 0.3644 - val_loss: 1.0981 - val_acc: 0.3330\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 2)         56        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32, 32, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 16, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 4)         76        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 16, 16, 4)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 4)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 8)           296       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 2, 2, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 5,039\n",
      "Trainable params: 5,039\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "5039\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 13s - loss: 1.0989 - acc: 0.37 - ETA: 8s - loss: 1.1039 - acc: 0.3281 - ETA: 8s - loss: 1.1032 - acc: 0.302 - ETA: 8s - loss: 1.1018 - acc: 0.335 - ETA: 7s - loss: 1.1012 - acc: 0.343 - ETA: 7s - loss: 1.1009 - acc: 0.333 - ETA: 6s - loss: 1.0997 - acc: 0.343 - ETA: 6s - loss: 1.0990 - acc: 0.343 - ETA: 6s - loss: 1.0988 - acc: 0.343 - ETA: 6s - loss: 1.0986 - acc: 0.340 - ETA: 6s - loss: 1.0991 - acc: 0.326 - ETA: 5s - loss: 1.0995 - acc: 0.315 - ETA: 5s - loss: 1.0997 - acc: 0.302 - ETA: 5s - loss: 1.0998 - acc: 0.305 - ETA: 5s - loss: 1.0998 - acc: 0.310 - ETA: 5s - loss: 1.0998 - acc: 0.310 - ETA: 5s - loss: 1.0995 - acc: 0.316 - ETA: 5s - loss: 1.0994 - acc: 0.321 - ETA: 5s - loss: 1.0996 - acc: 0.324 - ETA: 5s - loss: 1.0992 - acc: 0.331 - ETA: 4s - loss: 1.0993 - acc: 0.322 - ETA: 4s - loss: 1.0993 - acc: 0.322 - ETA: 4s - loss: 1.0994 - acc: 0.319 - ETA: 4s - loss: 1.0995 - acc: 0.313 - ETA: 4s - loss: 1.0997 - acc: 0.312 - ETA: 4s - loss: 1.0997 - acc: 0.310 - ETA: 3s - loss: 1.0996 - acc: 0.307 - ETA: 3s - loss: 1.0996 - acc: 0.306 - ETA: 3s - loss: 1.0997 - acc: 0.305 - ETA: 3s - loss: 1.0997 - acc: 0.303 - ETA: 3s - loss: 1.0995 - acc: 0.310 - ETA: 3s - loss: 1.0994 - acc: 0.313 - ETA: 3s - loss: 1.0994 - acc: 0.314 - ETA: 2s - loss: 1.0994 - acc: 0.313 - ETA: 2s - loss: 1.0993 - acc: 0.317 - ETA: 2s - loss: 1.0991 - acc: 0.318 - ETA: 2s - loss: 1.0990 - acc: 0.321 - ETA: 2s - loss: 1.0989 - acc: 0.322 - ETA: 1s - loss: 1.0989 - acc: 0.319 - ETA: 1s - loss: 1.0988 - acc: 0.321 - ETA: 1s - loss: 1.0988 - acc: 0.326 - ETA: 1s - loss: 1.0988 - acc: 0.325 - ETA: 1s - loss: 1.0988 - acc: 0.324 - ETA: 1s - loss: 1.0988 - acc: 0.322 - ETA: 0s - loss: 1.0989 - acc: 0.322 - ETA: 0s - loss: 1.0989 - acc: 0.322 - ETA: 0s - loss: 1.0990 - acc: 0.321 - ETA: 0s - loss: 1.0990 - acc: 0.320 - ETA: 0s - loss: 1.0987 - acc: 0.325 - 9s - loss: 1.0987 - acc: 0.3256 - val_loss: 1.0988 - val_acc: 0.3330\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 4)         112       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 32, 32, 4)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 8)         296       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 16)          1168      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 10,283\n",
      "Trainable params: 10,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "10283\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - ETA: 8s - loss: 1.0860 - acc: 0.437 - ETA: 5s - loss: 1.0985 - acc: 0.406 - ETA: 5s - loss: 1.0997 - acc: 0.406 - ETA: 5s - loss: 1.0924 - acc: 0.406 - ETA: 5s - loss: 1.0951 - acc: 0.387 - ETA: 5s - loss: 1.0954 - acc: 0.375 - ETA: 5s - loss: 1.1023 - acc: 0.361 - ETA: 4s - loss: 1.1039 - acc: 0.355 - ETA: 4s - loss: 1.1045 - acc: 0.354 - ETA: 4s - loss: 1.1019 - acc: 0.359 - ETA: 4s - loss: 1.1018 - acc: 0.358 - ETA: 4s - loss: 1.1033 - acc: 0.354 - ETA: 4s - loss: 1.1014 - acc: 0.351 - ETA: 4s - loss: 1.1010 - acc: 0.352 - ETA: 4s - loss: 1.0996 - acc: 0.358 - ETA: 4s - loss: 1.1014 - acc: 0.353 - ETA: 3s - loss: 1.1006 - acc: 0.358 - ETA: 3s - loss: 1.1012 - acc: 0.354 - ETA: 3s - loss: 1.1017 - acc: 0.348 - ETA: 3s - loss: 1.1015 - acc: 0.346 - ETA: 3s - loss: 1.1013 - acc: 0.346 - ETA: 3s - loss: 1.1020 - acc: 0.342 - ETA: 3s - loss: 1.1018 - acc: 0.341 - ETA: 3s - loss: 1.1014 - acc: 0.341 - ETA: 3s - loss: 1.1016 - acc: 0.340 - ETA: 2s - loss: 1.1009 - acc: 0.345 - ETA: 2s - loss: 1.1017 - acc: 0.335 - ETA: 2s - loss: 1.1017 - acc: 0.335 - ETA: 2s - loss: 1.1015 - acc: 0.338 - ETA: 2s - loss: 1.1014 - acc: 0.336 - ETA: 2s - loss: 1.1013 - acc: 0.337 - ETA: 2s - loss: 1.1013 - acc: 0.335 - ETA: 2s - loss: 1.1012 - acc: 0.340 - ETA: 1s - loss: 1.1010 - acc: 0.341 - ETA: 1s - loss: 1.1008 - acc: 0.344 - ETA: 1s - loss: 1.1009 - acc: 0.344 - ETA: 1s - loss: 1.1010 - acc: 0.341 - ETA: 1s - loss: 1.1009 - acc: 0.342 - ETA: 1s - loss: 1.1008 - acc: 0.344 - ETA: 1s - loss: 1.1010 - acc: 0.341 - ETA: 1s - loss: 1.1009 - acc: 0.341 - ETA: 0s - loss: 1.1009 - acc: 0.340 - ETA: 0s - loss: 1.1008 - acc: 0.341 - ETA: 0s - loss: 1.1009 - acc: 0.340 - ETA: 0s - loss: 1.1008 - acc: 0.341 - ETA: 0s - loss: 1.1006 - acc: 0.342 - ETA: 0s - loss: 1.1003 - acc: 0.344 - ETA: 0s - loss: 1.1003 - acc: 0.344 - ETA: 0s - loss: 1.1001 - acc: 0.343 - 6s - loss: 1.1001 - acc: 0.3438 - val_loss: 1.0954 - val_acc: 0.3840\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 8)         224       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 22,931\n",
      "Trainable params: 22,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "22931\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - ETA: 9s - loss: 1.0976 - acc: 0.281 - ETA: 6s - loss: 1.1014 - acc: 0.281 - ETA: 6s - loss: 1.1007 - acc: 0.281 - ETA: 6s - loss: 1.1012 - acc: 0.289 - ETA: 6s - loss: 1.0971 - acc: 0.325 - ETA: 6s - loss: 1.1026 - acc: 0.296 - ETA: 5s - loss: 1.1050 - acc: 0.290 - ETA: 5s - loss: 1.1014 - acc: 0.316 - ETA: 5s - loss: 1.1016 - acc: 0.322 - ETA: 5s - loss: 1.0999 - acc: 0.337 - ETA: 5s - loss: 1.1004 - acc: 0.340 - ETA: 5s - loss: 1.0986 - acc: 0.354 - ETA: 5s - loss: 1.0989 - acc: 0.355 - ETA: 5s - loss: 1.0989 - acc: 0.359 - ETA: 4s - loss: 1.1000 - acc: 0.354 - ETA: 4s - loss: 1.0998 - acc: 0.349 - ETA: 4s - loss: 1.1014 - acc: 0.340 - ETA: 4s - loss: 1.1020 - acc: 0.333 - ETA: 4s - loss: 1.1009 - acc: 0.338 - ETA: 4s - loss: 1.1008 - acc: 0.337 - ETA: 4s - loss: 1.1007 - acc: 0.336 - ETA: 3s - loss: 1.1001 - acc: 0.342 - ETA: 3s - loss: 1.1003 - acc: 0.339 - ETA: 3s - loss: 1.1001 - acc: 0.342 - ETA: 3s - loss: 1.0996 - acc: 0.340 - ETA: 3s - loss: 1.0997 - acc: 0.340 - ETA: 3s - loss: 1.1000 - acc: 0.338 - ETA: 3s - loss: 1.0996 - acc: 0.339 - ETA: 2s - loss: 1.0994 - acc: 0.340 - ETA: 2s - loss: 1.0996 - acc: 0.339 - ETA: 2s - loss: 1.0990 - acc: 0.344 - ETA: 2s - loss: 1.0991 - acc: 0.346 - ETA: 2s - loss: 1.0988 - acc: 0.349 - ETA: 2s - loss: 1.0990 - acc: 0.349 - ETA: 2s - loss: 1.0988 - acc: 0.347 - ETA: 1s - loss: 1.0991 - acc: 0.346 - ETA: 1s - loss: 1.0994 - acc: 0.343 - ETA: 1s - loss: 1.0995 - acc: 0.342 - ETA: 1s - loss: 1.0994 - acc: 0.342 - ETA: 1s - loss: 1.0993 - acc: 0.343 - ETA: 1s - loss: 1.0993 - acc: 0.340 - ETA: 1s - loss: 1.0993 - acc: 0.340 - ETA: 0s - loss: 1.0990 - acc: 0.340 - ETA: 0s - loss: 1.0990 - acc: 0.338 - ETA: 0s - loss: 1.0989 - acc: 0.342 - ETA: 0s - loss: 1.0991 - acc: 0.341 - ETA: 0s - loss: 1.0988 - acc: 0.344 - ETA: 0s - loss: 1.0986 - acc: 0.345 - ETA: 0s - loss: 1.0987 - acc: 0.346 - 7s - loss: 1.0987 - acc: 0.3475 - val_loss: 1.0999 - val_acc: 0.3460\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 56,867\n",
      "Trainable params: 56,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "56867\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - ETA: 12s - loss: 1.1018 - acc: 0.31 - ETA: 7s - loss: 1.1072 - acc: 0.3125 - ETA: 7s - loss: 1.1018 - acc: 0.322 - ETA: 7s - loss: 1.1062 - acc: 0.328 - ETA: 7s - loss: 1.1054 - acc: 0.318 - ETA: 7s - loss: 1.1053 - acc: 0.302 - ETA: 6s - loss: 1.1058 - acc: 0.308 - ETA: 6s - loss: 1.1022 - acc: 0.328 - ETA: 6s - loss: 1.1006 - acc: 0.329 - ETA: 6s - loss: 1.1017 - acc: 0.321 - ETA: 6s - loss: 1.1014 - acc: 0.329 - ETA: 6s - loss: 1.0975 - acc: 0.341 - ETA: 5s - loss: 1.0957 - acc: 0.351 - ETA: 5s - loss: 1.0940 - acc: 0.352 - ETA: 5s - loss: 1.0981 - acc: 0.345 - ETA: 5s - loss: 1.0975 - acc: 0.351 - ETA: 5s - loss: 1.0984 - acc: 0.354 - ETA: 5s - loss: 1.0971 - acc: 0.359 - ETA: 4s - loss: 1.0968 - acc: 0.366 - ETA: 4s - loss: 1.0939 - acc: 0.370 - ETA: 4s - loss: 1.0960 - acc: 0.370 - ETA: 4s - loss: 1.0965 - acc: 0.363 - ETA: 4s - loss: 1.0964 - acc: 0.361 - ETA: 4s - loss: 1.0973 - acc: 0.360 - ETA: 3s - loss: 1.0968 - acc: 0.367 - ETA: 3s - loss: 1.0975 - acc: 0.366 - ETA: 3s - loss: 1.0969 - acc: 0.366 - ETA: 3s - loss: 1.0961 - acc: 0.370 - ETA: 3s - loss: 1.0951 - acc: 0.377 - ETA: 3s - loss: 1.0952 - acc: 0.377 - ETA: 3s - loss: 1.0946 - acc: 0.382 - ETA: 2s - loss: 1.0948 - acc: 0.384 - ETA: 2s - loss: 1.0951 - acc: 0.385 - ETA: 2s - loss: 1.0951 - acc: 0.382 - ETA: 2s - loss: 1.0948 - acc: 0.384 - ETA: 2s - loss: 1.0949 - acc: 0.384 - ETA: 2s - loss: 1.0945 - acc: 0.385 - ETA: 1s - loss: 1.0938 - acc: 0.386 - ETA: 1s - loss: 1.0942 - acc: 0.386 - ETA: 1s - loss: 1.0947 - acc: 0.385 - ETA: 1s - loss: 1.0953 - acc: 0.381 - ETA: 1s - loss: 1.0953 - acc: 0.379 - ETA: 1s - loss: 1.0954 - acc: 0.378 - ETA: 0s - loss: 1.0950 - acc: 0.379 - ETA: 0s - loss: 1.0946 - acc: 0.381 - ETA: 0s - loss: 1.0945 - acc: 0.381 - ETA: 0s - loss: 1.0944 - acc: 0.383 - ETA: 0s - loss: 1.0943 - acc: 0.382 - ETA: 0s - loss: 1.0944 - acc: 0.383 - 9s - loss: 1.0944 - acc: 0.3831 - val_loss: 1.0960 - val_acc: 0.4000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_24 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 159,299\n",
      "Trainable params: 159,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "159299\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - ETA: 16s - loss: 1.1021 - acc: 0.28 - ETA: 11s - loss: 1.0994 - acc: 0.34 - ETA: 11s - loss: 1.0999 - acc: 0.38 - ETA: 10s - loss: 1.0963 - acc: 0.38 - ETA: 9s - loss: 1.0942 - acc: 0.3812 - ETA: 9s - loss: 1.1016 - acc: 0.369 - ETA: 9s - loss: 1.0985 - acc: 0.379 - ETA: 9s - loss: 1.0960 - acc: 0.390 - ETA: 8s - loss: 1.0964 - acc: 0.399 - ETA: 8s - loss: 1.0972 - acc: 0.396 - ETA: 8s - loss: 1.1017 - acc: 0.380 - ETA: 8s - loss: 1.1006 - acc: 0.377 - ETA: 8s - loss: 1.0970 - acc: 0.379 - ETA: 7s - loss: 1.0950 - acc: 0.381 - ETA: 7s - loss: 1.0956 - acc: 0.375 - ETA: 7s - loss: 1.0990 - acc: 0.367 - ETA: 7s - loss: 1.0977 - acc: 0.375 - ETA: 6s - loss: 1.0986 - acc: 0.378 - ETA: 6s - loss: 1.0999 - acc: 0.373 - ETA: 6s - loss: 1.0997 - acc: 0.371 - ETA: 6s - loss: 1.0994 - acc: 0.372 - ETA: 6s - loss: 1.1007 - acc: 0.367 - ETA: 5s - loss: 1.1010 - acc: 0.368 - ETA: 5s - loss: 1.1017 - acc: 0.363 - ETA: 5s - loss: 1.1019 - acc: 0.363 - ETA: 5s - loss: 1.1012 - acc: 0.365 - ETA: 4s - loss: 1.1008 - acc: 0.369 - ETA: 4s - loss: 1.1015 - acc: 0.363 - ETA: 4s - loss: 1.1012 - acc: 0.362 - ETA: 4s - loss: 1.1008 - acc: 0.364 - ETA: 4s - loss: 1.1010 - acc: 0.362 - ETA: 3s - loss: 1.1009 - acc: 0.364 - ETA: 3s - loss: 1.1007 - acc: 0.361 - ETA: 3s - loss: 1.1005 - acc: 0.364 - ETA: 3s - loss: 1.1004 - acc: 0.363 - ETA: 2s - loss: 1.1001 - acc: 0.363 - ETA: 2s - loss: 1.1003 - acc: 0.360 - ETA: 2s - loss: 1.1002 - acc: 0.361 - ETA: 2s - loss: 1.0998 - acc: 0.363 - ETA: 2s - loss: 1.0998 - acc: 0.362 - ETA: 1s - loss: 1.0998 - acc: 0.361 - ETA: 1s - loss: 1.0997 - acc: 0.363 - ETA: 1s - loss: 1.0998 - acc: 0.360 - ETA: 1s - loss: 1.0998 - acc: 0.358 - ETA: 1s - loss: 1.0997 - acc: 0.359 - ETA: 0s - loss: 1.0997 - acc: 0.358 - ETA: 0s - loss: 1.0998 - acc: 0.356 - ETA: 0s - loss: 1.0997 - acc: 0.357 - ETA: 0s - loss: 1.0994 - acc: 0.359 - 12s - loss: 1.0994 - acc: 0.3575 - val_loss: 1.0991 - val_acc: 0.3330\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 48)        1344      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 32, 32, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 96)        41568     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 8, 8, 192)         166080    \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 2, 2, 192)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 307,811\n",
      "Trainable params: 307,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "307811\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - ETA: 29s - loss: 1.0787 - acc: 0.37 - ETA: 21s - loss: 1.1147 - acc: 0.32 - ETA: 18s - loss: 1.1362 - acc: 0.28 - ETA: 16s - loss: 1.1338 - acc: 0.27 - ETA: 15s - loss: 1.1250 - acc: 0.30 - ETA: 15s - loss: 1.1199 - acc: 0.31 - ETA: 14s - loss: 1.1149 - acc: 0.32 - ETA: 13s - loss: 1.1110 - acc: 0.33 - ETA: 13s - loss: 1.1133 - acc: 0.33 - ETA: 13s - loss: 1.1138 - acc: 0.33 - ETA: 12s - loss: 1.1142 - acc: 0.34 - ETA: 12s - loss: 1.1147 - acc: 0.34 - ETA: 11s - loss: 1.1153 - acc: 0.33 - ETA: 11s - loss: 1.1133 - acc: 0.33 - ETA: 11s - loss: 1.1128 - acc: 0.33 - ETA: 10s - loss: 1.1119 - acc: 0.33 - ETA: 10s - loss: 1.1108 - acc: 0.33 - ETA: 9s - loss: 1.1103 - acc: 0.3299 - ETA: 9s - loss: 1.1095 - acc: 0.330 - ETA: 9s - loss: 1.1092 - acc: 0.323 - ETA: 8s - loss: 1.1092 - acc: 0.321 - ETA: 8s - loss: 1.1085 - acc: 0.325 - ETA: 8s - loss: 1.1084 - acc: 0.322 - ETA: 7s - loss: 1.1078 - acc: 0.321 - ETA: 7s - loss: 1.1070 - acc: 0.327 - ETA: 7s - loss: 1.1067 - acc: 0.324 - ETA: 6s - loss: 1.1062 - acc: 0.324 - ETA: 6s - loss: 1.1059 - acc: 0.323 - ETA: 6s - loss: 1.1058 - acc: 0.323 - ETA: 6s - loss: 1.1046 - acc: 0.330 - ETA: 5s - loss: 1.1045 - acc: 0.332 - ETA: 5s - loss: 1.1041 - acc: 0.334 - ETA: 5s - loss: 1.1042 - acc: 0.334 - ETA: 4s - loss: 1.1040 - acc: 0.337 - ETA: 4s - loss: 1.1036 - acc: 0.341 - ETA: 4s - loss: 1.1038 - acc: 0.340 - ETA: 4s - loss: 1.1043 - acc: 0.337 - ETA: 3s - loss: 1.1039 - acc: 0.338 - ETA: 3s - loss: 1.1045 - acc: 0.335 - ETA: 3s - loss: 1.1046 - acc: 0.339 - ETA: 3s - loss: 1.1046 - acc: 0.339 - ETA: 2s - loss: 1.1043 - acc: 0.342 - ETA: 2s - loss: 1.1045 - acc: 0.340 - ETA: 2s - loss: 1.1042 - acc: 0.342 - ETA: 1s - loss: 1.1042 - acc: 0.341 - ETA: 1s - loss: 1.1042 - acc: 0.340 - ETA: 1s - loss: 1.1040 - acc: 0.339 - ETA: 0s - loss: 1.1038 - acc: 0.343 - ETA: 0s - loss: 1.1037 - acc: 0.345 - 20s - loss: 1.1037 - acc: 0.3431 - val_loss: 1.0982 - val_acc: 0.3620\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 64)        1792      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_10 (Averag (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 502,403\n",
      "Trainable params: 502,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "502403\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - ETA: 38s - loss: 1.1029 - acc: 0.37 - ETA: 30s - loss: 1.0975 - acc: 0.40 - ETA: 28s - loss: 1.1626 - acc: 0.36 - ETA: 27s - loss: 1.1498 - acc: 0.36 - ETA: 27s - loss: 1.1460 - acc: 0.36 - ETA: 27s - loss: 1.1369 - acc: 0.38 - ETA: 26s - loss: 1.1425 - acc: 0.38 - ETA: 26s - loss: 1.1424 - acc: 0.37 - ETA: 25s - loss: 1.1323 - acc: 0.38 - ETA: 24s - loss: 1.1386 - acc: 0.38 - ETA: 23s - loss: 1.1362 - acc: 0.37 - ETA: 23s - loss: 1.1384 - acc: 0.37 - ETA: 22s - loss: 1.1340 - acc: 0.37 - ETA: 21s - loss: 1.1318 - acc: 0.37 - ETA: 21s - loss: 1.1322 - acc: 0.36 - ETA: 20s - loss: 1.1321 - acc: 0.35 - ETA: 19s - loss: 1.1310 - acc: 0.35 - ETA: 18s - loss: 1.1299 - acc: 0.34 - ETA: 17s - loss: 1.1286 - acc: 0.34 - ETA: 17s - loss: 1.1271 - acc: 0.34 - ETA: 16s - loss: 1.1257 - acc: 0.34 - ETA: 15s - loss: 1.1243 - acc: 0.34 - ETA: 14s - loss: 1.1231 - acc: 0.34 - ETA: 14s - loss: 1.1222 - acc: 0.34 - ETA: 13s - loss: 1.1216 - acc: 0.33 - ETA: 13s - loss: 1.1206 - acc: 0.33 - ETA: 12s - loss: 1.1198 - acc: 0.33 - ETA: 12s - loss: 1.1189 - acc: 0.33 - ETA: 11s - loss: 1.1183 - acc: 0.33 - ETA: 10s - loss: 1.1177 - acc: 0.33 - ETA: 10s - loss: 1.1170 - acc: 0.33 - ETA: 9s - loss: 1.1164 - acc: 0.3330 - ETA: 9s - loss: 1.1160 - acc: 0.327 - ETA: 8s - loss: 1.1157 - acc: 0.322 - ETA: 8s - loss: 1.1151 - acc: 0.322 - ETA: 7s - loss: 1.1145 - acc: 0.325 - ETA: 7s - loss: 1.1142 - acc: 0.325 - ETA: 6s - loss: 1.1139 - acc: 0.324 - ETA: 6s - loss: 1.1138 - acc: 0.319 - ETA: 5s - loss: 1.1133 - acc: 0.321 - ETA: 4s - loss: 1.1128 - acc: 0.323 - ETA: 4s - loss: 1.1123 - acc: 0.325 - ETA: 3s - loss: 1.1122 - acc: 0.324 - ETA: 3s - loss: 1.1120 - acc: 0.326 - ETA: 2s - loss: 1.1116 - acc: 0.328 - ETA: 2s - loss: 1.1112 - acc: 0.329 - ETA: 1s - loss: 1.1110 - acc: 0.329 - ETA: 1s - loss: 1.1105 - acc: 0.332 - ETA: 0s - loss: 1.1102 - acc: 0.334 - 31s - loss: 1.1100 - acc: 0.3350 - val_loss: 1.1031 - val_acc: 0.3300\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 384)         663936    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_11 (Averag (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,029,827\n",
      "Trainable params: 1,029,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "1029827\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 63s - loss: 1.0978 - acc: 0.43 - ETA: 58s - loss: 1.0797 - acc: 0.39 - ETA: 56s - loss: 1.1842 - acc: 0.38 - ETA: 52s - loss: 1.2114 - acc: 0.36 - ETA: 48s - loss: 1.1886 - acc: 0.36 - ETA: 46s - loss: 1.1730 - acc: 0.35 - ETA: 44s - loss: 1.1662 - acc: 0.34 - ETA: 42s - loss: 1.1588 - acc: 0.33 - ETA: 41s - loss: 1.1512 - acc: 0.33 - ETA: 40s - loss: 1.1477 - acc: 0.33 - ETA: 38s - loss: 1.1443 - acc: 0.33 - ETA: 37s - loss: 1.1387 - acc: 0.34 - ETA: 36s - loss: 1.1351 - acc: 0.34 - ETA: 35s - loss: 1.1324 - acc: 0.34 - ETA: 33s - loss: 1.1305 - acc: 0.35 - ETA: 32s - loss: 1.1286 - acc: 0.35 - ETA: 31s - loss: 1.1259 - acc: 0.35 - ETA: 30s - loss: 1.1217 - acc: 0.36 - ETA: 30s - loss: 1.1213 - acc: 0.36 - ETA: 29s - loss: 1.1184 - acc: 0.36 - ETA: 28s - loss: 1.1191 - acc: 0.36 - ETA: 26s - loss: 1.1200 - acc: 0.35 - ETA: 25s - loss: 1.1201 - acc: 0.35 - ETA: 24s - loss: 1.1210 - acc: 0.35 - ETA: 23s - loss: 1.1207 - acc: 0.34 - ETA: 22s - loss: 1.1199 - acc: 0.34 - ETA: 21s - loss: 1.1194 - acc: 0.34 - ETA: 20s - loss: 1.1183 - acc: 0.34 - ETA: 19s - loss: 1.1176 - acc: 0.34 - ETA: 18s - loss: 1.1165 - acc: 0.35 - ETA: 17s - loss: 1.1160 - acc: 0.35 - ETA: 16s - loss: 1.1150 - acc: 0.35 - ETA: 15s - loss: 1.1146 - acc: 0.35 - ETA: 14s - loss: 1.1143 - acc: 0.35 - ETA: 13s - loss: 1.1140 - acc: 0.35 - ETA: 13s - loss: 1.1137 - acc: 0.35 - ETA: 12s - loss: 1.1132 - acc: 0.35 - ETA: 11s - loss: 1.1127 - acc: 0.35 - ETA: 10s - loss: 1.1126 - acc: 0.34 - ETA: 9s - loss: 1.1121 - acc: 0.3500 - ETA: 8s - loss: 1.1114 - acc: 0.352 - ETA: 7s - loss: 1.1109 - acc: 0.354 - ETA: 6s - loss: 1.1101 - acc: 0.355 - ETA: 5s - loss: 1.1105 - acc: 0.351 - ETA: 4s - loss: 1.1103 - acc: 0.350 - ETA: 3s - loss: 1.1101 - acc: 0.351 - ETA: 2s - loss: 1.1095 - acc: 0.354 - ETA: 1s - loss: 1.1093 - acc: 0.354 - ETA: 0s - loss: 1.1091 - acc: 0.355 - 54s - loss: 1.1090 - acc: 0.3538 - val_loss: 1.0994 - val_acc: 0.3330\n"
     ]
    }
   ],
   "source": [
    "# Train many models\n",
    "for filters in [1,2,4,8,16,32,48,64,96]:\n",
    "    modelid = \"filters{:03d}_timestamp{}\".format(filters,time.strftime(\"%Y%m%d%H%M%S\"))\n",
    "\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_acc',\n",
    "            patience=50),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath='model_checkpoint_best_{}.h5'.format(modelid),\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir='./logs/'+modelid,\n",
    "            histogram_freq=0, write_graph=False, write_images=False)\n",
    "    ]\n",
    "    \n",
    "    model = makeModel(filters)\n",
    "    print(model.summary())\n",
    "    print(model.count_params())\n",
    "\n",
    "    history=model.fit_generator(\n",
    "                        generator(dataset_tr, batch_size, patchsize),\n",
    "                        steps_per_epoch=50, \n",
    "                        epochs=1, \n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test,y_test),\n",
    "                        callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 6: Process the images of the testing set one by one\n",
    "And visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = 'models/model_venus.model', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-dd3a97182d8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodelname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"models/model_venus\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}.model\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpatchsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdataset_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}.testingdata.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[1;31m# instantiate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1490029679460\\work\\h5py\\_objects.c:2867)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1490029679460\\work\\h5py\\_objects.c:2825)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (C:\\Minonda\\conda-bld\\h5py_1490029679460\\work\\h5py\\h5f.c:2140)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = 'models/model_venus.model', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Optionally, load a saved model and testing dataset\n",
    "modelname = \"models/model_venus\"\n",
    "\n",
    "model = keras.models.load_model(\"{}.model\".format(modelname))\n",
    "patchsize = model.input.shape[1].value\n",
    "dataset_te = pd.read_pickle(\"{}.testingdata.pickle\".format(modelname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222e5d4dabfd4374bff81b91b36b549b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.resultsShow>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results by processing a single variation of the testing image\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "def resultsShow(i, data, model):\n",
    "    d = data.iloc[i]\n",
    "    im = d[\"image\"]\n",
    "    l = d[\"label\"]\n",
    "    fig,axs = plt.subplots(nrows=1,ncols=3,figsize=(15,5),gridspec_kw={'width_ratios':[1,1,0.5]})\n",
    "    \n",
    "    imt = transform_simple(im, patchsize)\n",
    "    axs[0].imshow(im)\n",
    "    axs[0].set_title(\"Image (true class: {})\".format(names[l]))\n",
    "    \n",
    "    axs[1].imshow(imt,interpolation=\"nearest\")\n",
    "    axs[1].set_title(\"Network input\")\n",
    "    \n",
    "    outs = model.predict(np.array([imt]))\n",
    "    print(outs)\n",
    "    predicted = np.argmax(outs)\n",
    "    axs[2].bar(np.array(range(len(names))), outs[0,:], 1, color=\"gray\")\n",
    "    axs[2].set_ylim([0,1])\n",
    "    axs[2].set_xticks(range(len(names)))\n",
    "    axs[2].set_xticklabels(names)\n",
    "    axs[2].set_ylabel(\"probability\")\n",
    "    axs[2].set_xlabel(\"class\")\n",
    "    axs[2].set_title(\"Network output\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(\"out_{:05d}_{}.png\".format(i,(\"ok\" if predicted==l else \"ko\")))\n",
    "    print(outs)\n",
    "\n",
    "interact(resultsShow, i=widgets.IntSlider(min=0,max=len(dataset_te)-1, step=1, value=0, continuous_update=False), data=fixed(dataset_te.sample(len(dataset_te))), model=fixed(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's visualize the filters learned by the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 384)         663936    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_11 (Averag (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,029,827\n",
      "Trainable params: 1,029,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06982982,  0.05976203,  0.07515687],\n",
       "       [-0.00157245, -0.03450482,  0.02439579],\n",
       "       [ 0.066213  ,  0.05729593,  0.0252305 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0][:,:,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4e3620ba1b6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize filters in a layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Visualize filters in a layer\n",
    "import itertools\n",
    "filters = model.layers[2].get_weights()[0]\n",
    "filters.shape\n",
    "fig, axs = plt.subplots(nrows = filters.shape[2], ncols = filters.shape[3], figsize=(20,10))\n",
    "for i,j in itertools.product(range(filters.shape[2]),range(filters.shape[3])):\n",
    "    axs[i,j].imshow(filters[:,:,i,j],vmin=-0.5,vmax=+0.5,cmap=\"gray\")\n",
    "    axs[i,j].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's visualize the activations in the intermediate layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBYAAAKzCAYAAACqI47NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20328367cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def plot_hidden_layers(imt,nmaps=4):\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    plt.title('Hidden layers', loc='center')\n",
    "    plt.axis('off')\n",
    "    layers = [model.layers[0].input] + [model.layers[i].output for i in [0,2,5,7,9]]\n",
    "    for layeri,layer in enumerate(layers):\n",
    "        get = K.function([model.layers[0].input], [layer])\n",
    "        layeroutputs = get([imt[np.newaxis,:,:,:]])[0][0]\n",
    "        for j in range(nmaps): # for each map\n",
    "            sp2=fig.add_subplot(nmaps,len(layers),layeri+1+j*len(layers))\n",
    "            sp2.axis('off')\n",
    "            if (layeroutputs.shape[2]>j):\n",
    "                vmin,vmax = ((0,1) if layeri == 0 else (-0.3,+0.3))\n",
    "                sp2.imshow(layeroutputs[:,:,j],\n",
    "                           cmap=\"gray\",\n",
    "                           interpolation=\"nearest\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "imt=transform(dataset_te[\"image\"].iloc[0],patchsize)\n",
    "plot_hidden_layers(imt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We now search for the inputs maximizing a given neuron or set of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 384)         663936    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_11 (Averag (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,029,827\n",
      "Trainable params: 1,029,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def makeinputmaximizing(loss, gradstep = 0.01, steps = 20):\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "    grads /= K.sqrt(K.mean(K.square(grads)) + 1e-5)\n",
    "    iterate = K.function([model.input, K.learning_phase()],[loss, grads])\n",
    "\n",
    "    # img = transform_simple(dataset_te[\"image\"].iloc[0],patchsize)[np.newaxis,:,:,:]\n",
    "    img = 0.5+0.01*np.random.rand(1,patchsize,patchsize,3)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        loss_value, grads_value = iterate([img, 1])\n",
    "#        if np.max(grads_value)>0:\n",
    "#            gradstep=1/np.max(grads_value)            \n",
    "        img += grads_value * gradstep\n",
    "        img = np.clip(img,0,1)\n",
    "    return img[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2032c63e668>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\negCQxKDrtvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2032c57f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(makeinputmaximizing(model.layers[6].output[0,2], steps = 1000, gradstep = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDwAAAEyCAYAAAAWWMA0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9Dj/P2E8IZoMquHeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20327b9d358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm\n",
    "out = model.layers[6].output\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 5, figsize=(20,5), squeeze = False)\n",
    "for i,j in tqdm.tqdm(list(itertools.product(range(axs.shape[0]), range(axs.shape[1])))):\n",
    "    loss = K.mean(out[:,j])\n",
    "    img = makeinputmaximizing(loss, gradstep = 0.03, steps = 20)\n",
    "    axs[i,j].imshow(img)\n",
    "    axs[i,j].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let us look for what the convnet considers an 'ideal paper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2033ac67470>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG4AAAD8CAYAAACW9ZGzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x203398dce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "final_output=np.zeros((patchsize*3, patchsize, 3))\n",
    "\n",
    "for k in range(3):\n",
    "    loss = model.output[0,k]        \n",
    "    final_output[0+k*patchsize:patchsize+k*patchsize,0:patchsize]=makeinputmaximizing(loss, gradstep=0.01, steps=20)\n",
    "plt.imshow(final_output[:,:,:], vmin=0, vmax=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let us try to locate the gesture in the image\n",
    "- First, we feed an image of a paper gesture to the network;\n",
    "- Second, we assign to each channel in the output of the last convolution a value corresponding ot its contribution to the class \"paper\";\n",
    "- Third, we consider which parts in the input image activate the channels that lead to the decision: this is a paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2032c4fdf28>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRAqDn5BIYfATEikMfkIihcFPSKT8H6I0FTLxnp/jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2032e5cac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img=skimage.img_as_float(skimage.io.imread(\"paper.jpg\"))\n",
    "img=np.expand_dims(img, axis=0)\n",
    "preds=model.predict(img)\n",
    "rps_output=model.output[:, np.argmax(preds[0])]\n",
    "last_conv_layer=model.layers[6]\n",
    "grads=K.gradients(rps_output, last_conv_layer.output)[0]\n",
    "pooled_grads=K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "iterate=K.function([model.input, K.learning_phase()], [pooled_grads, last_conv_layer.output[0]])\n",
    "pooled_grads_value, conv_layer_output_value = iterate([img, 1])\n",
    "##\n",
    "for i in range(5):\n",
    "    conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap=cv2.resize(heatmap, (img.shape[1], img.shape[2]))\n",
    "plt.imshow(heatmap)\n",
    "print(heatmap.shape)\n",
    "\n",
    "img=skimage.img_as_float(skimage.io.imread(\"paper.jpg\"))\n",
    "heatmap=np.expand_dims(heatmap, axis=3)\n",
    "superimposed_img= np.clip(img * 0.6 + heatmap , 0, 1)\n",
    "plt.imshow(superimposed_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "livereveal": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
